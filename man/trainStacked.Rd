% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trainTfModel.R
\name{trainStacked}
\alias{trainStacked}
\title{Training transcription factor-specific tree-based gradient boosting Models}
\usage{
trainStacked(
  featMat,
  modsBagged,
  stackingStrat = c("last", "wLast", "wMean", "boostTree"),
  subSample = 1e+05,
  evalRounds = 100,
  earlyStoppingRounds = 10,
  seed = 42,
  numThreads = 10,
  BPPARAM = SerialParam()
)
}
\arguments{
\item{featMat}{Labelled feature matrix as obtained with \link{getFeatureMatrix}. Ideally not used for training the bagged models.}

\item{modsBagged}{Bag of models trained on different stratas of the data, as obtained by \link{trainBagged}.}

\item{stackingStrat}{Stacking strategy to use. \code{last}, chooses the the model which has been trained on all (most) positives not using
observational weights for the ChIP-seq peaks. \code{wLast} using the last model which has seen most positives and has been trained with observational weights.
\code{wMean} weighted mean all models based on performance on the feature matrix provided.
\code{boostTree} Trains a lightgbm model on the predictions of the models in the bag, together with some additional features (e.g. gc_content, total_overlaps).}

\item{subSample}{Number of rows of featMat whoich should be used for computing performance estimates. Only used if \code{stackingStrat="wMean"}-}

\item{evalRounds}{Number of evaluation rounds for the hyperparameter selection rounds. Only used if \code{stackingStrat="wBoost"}.}

\item{earlyStoppingRounds}{Number of early stopping rounds for the hyperparameter selection and training of the \link[lightgbm:lightgbm]{lightgbm::lightgbm} model. Only used if \code{stackingStrat="wBoost"}.}

\item{seed}{Integer value for setting the seed for random number generation with \link[base:Random]{base::set.seed}.}

\item{numThreads}{Total number of threads to be used. In case \link[BiocParallel:MulticoreParam-class]{BiocParallel::MulticoreParam} or \link[BiocParallel:SnowParam-class]{BiocParallel::SnowParam} with several workers are
are specified as parallel back-ends, \code{floor(numThreads/nWorker)} threads are used per worker.}

\item{BPPARAM}{Parallel back-end to be used. Passed to \code{\link[BiocParallel:bpmapply]{BiocParallel::bpmapply()}}.}
}
\value{
Stacked model. Depending on the strategy either a \link{lightgbm:lightgbm} model (\code{last}, \code{wLast}, \code{boostTree})
or a vector with weights for the models in the provided bag (\code{wMean}).
}
\description{
Trains a stacked model provided a bag of four tree-based gradient boosting models as obtained by \link{trainBagged}.
For different stacking strategies can be used.
}
